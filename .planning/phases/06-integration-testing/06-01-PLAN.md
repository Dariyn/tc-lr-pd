---
phase: 06-integration-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [main.py, src/orchestrator/__init__.py, src/orchestrator/pipeline_orchestrator.py, tests/test_pipeline_orchestrator.py]
autonomous: true
---

<objective>
Create unified pipeline orchestrator and CLI interface for end-to-end work order analysis.

Purpose: Provide single entry point that orchestrates all analysis modules (equipment, seasonal, vendor, failure patterns) and generates all output formats (PDF, Excel, CSV, JSON, charts, dashboard). Enables batch processing workflows for stakeholders.

Output: main.py CLI script and PipelineOrchestrator class that integrates all 16 existing modules into cohesive workflow.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase dependencies - understanding what to integrate
@.planning/phases/01-data-pipeline-foundation/01-04-SUMMARY.md
@.planning/phases/02-equipment-category-analysis/02-03-SUMMARY.md
@.planning/phases/03-cost-pattern-analysis/03-01-SUMMARY.md
@.planning/phases/03-cost-pattern-analysis/03-02-SUMMARY.md
@.planning/phases/03-cost-pattern-analysis/03-03-SUMMARY.md
@.planning/phases/04-reporting-engine/04-01-SUMMARY.md
@.planning/phases/04-reporting-engine/04-02-SUMMARY.md
@.planning/phases/04-reporting-engine/04-03-SUMMARY.md
@.planning/phases/05-data-export-visualization/05-01-SUMMARY.md
@.planning/phases/05-data-export-visualization/05-02-SUMMARY.md
@.planning/phases/05-data-export-visualization/05-03-SUMMARY.md

# Source modules to integrate
@src/pipeline/pipeline.py
@src/analysis/analysis_pipeline.py
@src/reporting/report_builder.py
@src/reporting/pdf_generator.py
@src/reporting/excel_generator.py
@src/exports/data_exporter.py
@src/visualization/chart_generator.py
@src/visualization/dashboard_generator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create PipelineOrchestrator class</name>
  <files>src/orchestrator/__init__.py, src/orchestrator/pipeline_orchestrator.py</files>
  <action>
Create src/orchestrator/ directory and PipelineOrchestrator class that integrates all analysis modules:

Class structure:
- __init__(self, input_file: str, output_dir: str = 'output'): Initialize with input file and output directory
- run_full_analysis(self) -> Dict: Execute complete pipeline and return results dict
  * Step 1: Data pipeline (load, clean, categorize, quality check)
  * Step 2: Equipment analysis (frequency, outlier detection, ranking)
  * Step 3: Seasonal analysis (monthly/quarterly patterns)
  * Step 4: Vendor analysis (cost performance, efficiency, quality)
  * Step 5: Failure pattern analysis (text extraction, categorization)
  * Return dict with: equipment_df, seasonal_dict, vendor_df, patterns_list, quality_report

- generate_reports(self, analysis_results: Dict) -> Dict[str, str]: Generate PDF and Excel reports
  * Use ReportBuilder to consolidate findings
  * Use PDFReportGenerator to create PDF
  * Use ExcelReportGenerator to create Excel
  * Return dict with file paths: {pdf_path, excel_path}

- export_data(self, analysis_results: Dict) -> Dict[str, List[str]]: Export CSV and JSON files
  * Use DataExporter for all 4 analysis types
  * Export both CSV and JSON for each type
  * Return dict with file paths organized by format

- generate_visualizations(self, analysis_results: Dict) -> Dict[str, List[str]]: Create charts and dashboard
  * Use ChartGenerator for static PNG/SVG charts
  * Use DashboardGenerator for interactive HTML
  * Return dict with file paths: {charts: [...], dashboard: path}

Integration notes:
- Use logging for progress updates at each stage
- Handle errors gracefully (if seasonal analysis has no data, skip it rather than crash)
- Create output directories if they don't exist (output/reports/, output/exports/, output/visualizations/)
- Follow existing patterns from analysis_pipeline.py for equipment analysis integration
- Ensure all file paths are returned for verification

Export __init__.py: from .pipeline_orchestrator import PipelineOrchestrator
  </action>
  <verify>pytest tests/test_pipeline_orchestrator.py -v -k "test_orchestrator_init or test_run_analysis"</verify>
  <done>PipelineOrchestrator class implemented with all 4 methods, integrates all 16 modules, handles errors gracefully</done>
</task>

<task type="auto">
  <name>Task 2: Create CLI interface with argparse</name>
  <files>main.py</files>
  <action>
Create main.py CLI script at project root with argparse interface:

Commands:
- analyze: Run full analysis pipeline
  * --input / -i: Path to input CSV/Excel file (required)
  * --output / -o: Output directory (default: output/)
  * --reports / -r: Generate PDF and Excel reports (flag, default: true)
  * --exports / -e: Export CSV and JSON data (flag, default: false)
  * --visualizations / -v: Generate charts and dashboard (flag, default: false)
  * --all / -a: Generate everything (reports + exports + visualizations)

Implementation:
- Parse arguments with argparse
- Validate input file exists
- Create PipelineOrchestrator instance
- Run analysis with run_full_analysis()
- Generate outputs based on flags (reports always run if -r not explicitly disabled)
- Print summary to console: files generated, output paths, execution time
- Exit with code 0 on success, code 1 on error

Example usage patterns in docstring:
```
# Basic analysis with PDF and Excel reports only (default)
python main.py analyze -i data/work_orders.csv

# Generate everything (reports + exports + visualizations)
python main.py analyze -i data/work_orders.csv --all

# Custom output directory with specific outputs
python main.py analyze -i data/work_orders.csv -o results/ --exports --visualizations
```

Add shebang #!/usr/bin/env python3 at top for Unix compatibility.
Include --help that shows clear usage instructions and examples.
  </action>
  <verify>python main.py --help && python main.py analyze --help</verify>
  <done>CLI interface implemented with clear help text, validates inputs, runs orchestrator, prints summary</done>
</task>

<task type="auto">
  <name>Task 3: Create comprehensive orchestrator tests</name>
  <files>tests/test_pipeline_orchestrator.py</files>
  <action>
Create comprehensive test suite for pipeline orchestration:

Setup:
- Use pytest fixtures for sample input data (small CSV with ~20 work orders)
- Use tmp_path fixture for output directories
- Mock heavy operations if needed (but prefer actual integration tests)

Tests (12 tests minimum):

Orchestrator initialization (2 tests):
- test_orchestrator_init: Verify initialization with input file
- test_orchestrator_output_dir_creation: Verify output directories created

Analysis execution (4 tests):
- test_run_full_analysis: Verify all analysis steps execute and return results dict
- test_run_full_analysis_results_structure: Verify results dict has correct keys and types
- test_run_full_analysis_empty_data: Handle empty input gracefully
- test_run_full_analysis_invalid_input: Handle invalid file path

Report generation (2 tests):
- test_generate_reports: Verify PDF and Excel files created
- test_generate_reports_file_validity: Verify files are valid (size > 0, correct format)

Export generation (2 tests):
- test_export_data: Verify CSV and JSON files created for all 4 analysis types
- test_export_data_file_counts: Verify correct number of files (8 total: 4 CSV + 4 JSON)

Visualization generation (2 tests):
- test_generate_visualizations: Verify charts (PNG) and dashboard (HTML) created
- test_generate_visualizations_file_validity: Verify files are valid formats

Use sample data that exercises all code paths. Test both success and error cases. Verify file existence and basic validity (size, format). Integration tests should run actual pipeline with real (small) data, not excessive mocking.
  </action>
  <verify>pytest tests/test_pipeline_orchestrator.py -v --cov=src/orchestrator</verify>
  <done>12+ tests covering orchestrator initialization, analysis execution, report/export/visualization generation, error handling. All tests pass with >85% coverage.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] pytest tests/test_pipeline_orchestrator.py passes all tests
- [ ] main.py CLI works: --help shows usage, analyze command runs
- [ ] PipelineOrchestrator integrates all 16 modules successfully
- [ ] Output files generated in correct directories with correct formats
- [ ] Error handling prevents crashes on edge cases
</verification>

<success_criteria>

- All tasks completed
- PipelineOrchestrator class orchestrates full pipeline (data → analysis → reports/exports/viz)
- CLI interface provides user-friendly access to pipeline
- Comprehensive test suite with 12+ tests passing
- Integration verified with actual data flow through all modules
- No errors or warnings introduced
  </success_criteria>

<output>
After completion, create `.planning/phases/06-integration-testing/06-01-SUMMARY.md`
</output>
