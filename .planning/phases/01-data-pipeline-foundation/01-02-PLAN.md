---
phase: 01-data-pipeline-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified: [src/pipeline/data_cleaner.py, tests/test_data_cleaner.py]
autonomous: true
---

<objective>
Implement data cleaning and standardization to handle missing values, outliers, and data quality issues.

Purpose: Ensure clean, consistent data for accurate downstream analysis by handling common data quality issues systematically.
Output: Data cleaning module with functions for handling nulls, outliers, and standardizing formats.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline-foundation/01-01-SUMMARY.md

**Core value from PROJECT:** Accurate identification of cost reduction opportunities

**Critical for accuracy:**
- Missing equipment IDs prevent category analysis
- Invalid costs skew financial analysis
- Incomplete dates break time-series analysis
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement data cleaning functions</name>
  <files>src/pipeline/data_cleaner.py</files>
  <action>
Create data_cleaner.py with modular cleaning functions:

**clean_equipment_data(df):**
- Drop rows where Equipment_ID is null AND EquipmentName is null (can't analyze without equipment identifier)
- For rows with Equipment_ID but missing EquipmentName, set EquipmentName = f"Unknown Equipment {Equipment_ID}"
- For rows with EquipmentName but missing Equipment_ID, create synthetic ID from name hash
- Standardize EquipmentName: strip whitespace, title case for consistency

**clean_cost_data(df):**
- PO_AMOUNT already converted to numeric in loader (NaN for invalid)
- Fill missing PO_AMOUNT with 0 (adhoc work may not have PO)
- Flag outliers: costs > 99th percentile get 'cost_outlier' flag column (don't remove - may be legitimate high-cost repairs)
- Ensure no negative costs (replace with 0, log warning)

**clean_date_data(df):**
- Create_Date, Complete_Date already converted to datetime in loader
- Drop rows missing Create_Date (can't analyze without creation date)
- For missing Complete_Date, check if Status_Eng == 'Closed' - if closed but no date, use Close_Date if available
- Calculate duration_hours = (Complete_Date - Create_Date).total_seconds() / 3600 for completed work orders
- Flag duration outliers: duration > 99th percentile gets 'duration_outlier' flag

**clean_work_orders(df):**
- Orchestrate all cleaning: equipment → cost → dates
- Return cleaned DataFrame with added columns: cost_outlier (bool), duration_outlier (bool), duration_hours (float)
- Log cleaning statistics: rows dropped, fields filled, outliers flagged
  </action>
  <verify>python -c "from src.pipeline.data_cleaner import clean_work_orders; from src.pipeline.data_loader import load_work_orders; df = load_work_orders('input/adhoc_wo_20240101_20250531.xlsx - in.csv'); cleaned = clean_work_orders(df); print(f'{len(cleaned)} rows after cleaning')" shows cleaned row count</verify>
  <done>Data cleaning functions handle nulls, standardize formats, flag outliers, and calculate derived fields</done>
</task>

<task type="auto">
  <name>Task 2: Create basic tests for cleaning logic</name>
  <files>tests/test_data_cleaner.py, tests/__init__.py</files>
  <action>
Create tests/test_data_cleaner.py with pytest tests:
- test_clean_equipment_data_drops_null_equipment: Verify rows with no equipment info are dropped
- test_clean_equipment_data_handles_partial_info: Verify synthetic IDs/names created
- test_clean_cost_data_fills_missing: Verify missing costs filled with 0
- test_clean_cost_data_removes_negatives: Verify negative costs replaced with 0
- test_clean_date_data_drops_missing_create: Verify rows without Create_Date dropped
- test_clean_date_data_calculates_duration: Verify duration_hours calculated correctly
- Add pytest to requirements.txt
- Use simple assert statements with small test DataFrames (no fixtures needed yet)
  </action>
  <verify>pytest tests/test_data_cleaner.py -v shows all tests passing</verify>
  <done>Test suite validates cleaning logic for equipment, cost, and date handling</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] src/pipeline/data_cleaner.py implements all cleaning functions
- [ ] Cleaning functions handle equipment, cost, and date data
- [ ] pytest tests/test_data_cleaner.py passes
- [ ] Verification command shows data successfully cleaned
</verification>

<success_criteria>

- All tasks completed
- Data cleaning handles nulls systematically
- Outliers flagged but not removed
- Tests validate cleaning logic
- No errors during cleaning process
  </success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline-foundation/01-02-SUMMARY.md`
</output>
