---
phase: 01-data-pipeline-foundation
plan: 04
type: execute
wave: 3
depends_on: ["01-02", "01-03"]
files_modified: [src/pipeline/quality_reporter.py, src/pipeline/pipeline.py]
autonomous: true
---

<objective>
Create data quality reporting system that validates cleaned and categorized data, providing confidence metrics for downstream analysis.

Purpose: Ensure data quality meets requirements for accurate cost reduction analysis by measuring completeness, consistency, and readiness.
Output: Quality reporter that generates comprehensive data quality metrics and integrated pipeline that orchestrates load → clean → categorize → validate.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline-foundation/01-01-SUMMARY.md
@.planning/phases/01-data-pipeline-foundation/01-02-SUMMARY.md
@.planning/phases/01-data-pipeline-foundation/01-03-SUMMARY.md

**Core value:** Accurate identification of cost reduction opportunities - requires high-quality data

**Quality dimensions from prior plans:**
- Completeness: Required fields populated (from 01-01)
- Cleanliness: Nulls handled, outliers flagged (from 01-02)
- Consistency: Categories normalized, equipment properly typed (from 01-03)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement data quality metrics</name>
  <files>src/pipeline/quality_reporter.py</files>
  <action>
Create quality_reporter.py with comprehensive quality assessment:

**calculate_completeness_metrics(df):**
- For each critical field (Equipment_ID, EquipmentName, equipment_category, Create_Date, Complete_Date, PO_AMOUNT):
  - Calculate % non-null
  - Count null values
- Return dict with field_name → completeness_pct
- Flag fields < 95% complete as quality concerns

**calculate_consistency_metrics(df):**
- Equipment category consistency: avg(equipment_category_consistency) from categorizer
- Date consistency: % of records with Complete_Date >= Create_Date
- Cost consistency: % of records with PO_AMOUNT >= 0
- Return dict with metric_name → value

**calculate_outlier_metrics(df):**
- Count and % of cost_outlier flagged records
- Count and % of duration_outlier flagged records
- Calculate outlier thresholds used (99th percentile values)
- Return dict with outlier counts and thresholds

**calculate_coverage_metrics(df):**
- Date range coverage: min(Create_Date) to max(Create_Date)
- Equipment coverage: unique Equipment_IDs count
- Category coverage: unique equipment_category count
- Property coverage: unique Property count
- Return dict with coverage statistics

**generate_quality_report(df):**
- Orchestrate all metric calculations
- Compile into single quality report dict with sections: completeness, consistency, outliers, coverage
- Calculate overall quality score: weighted avg of completeness (40%), consistency (40%), outlier rate (20%)
- Add quality_passed boolean: True if score >= 0.85
- Add recommendations list for any failing quality dimensions
- Return report dict
  </action>
  <verify>python -c "from src.pipeline.quality_reporter import generate_quality_report; from src.pipeline.data_loader import load_work_orders; from src.pipeline.data_cleaner import clean_work_orders; from src.pipeline.categorizer import categorize_work_orders; df = load_work_orders('input/adhoc_wo_20240101_20250531.xlsx - in.csv'); df = clean_work_orders(df); df = categorize_work_orders(df); report = generate_quality_report(df); print(f'Quality score: {report[\"overall_quality_score\"]:.2f}')" shows quality score</verify>
  <done>Quality reporter calculates completeness, consistency, outlier, and coverage metrics with overall quality scoring</done>
</task>

<task type="auto">
  <name>Task 2: Create integrated pipeline orchestrator</name>
  <files>src/pipeline/pipeline.py</files>
  <action>
Create pipeline.py to orchestrate complete data pipeline:

**run_pipeline(input_file, output_file=None):**
- Load data using data_loader.load_work_orders()
- Clean data using data_cleaner.clean_work_orders()
- Categorize data using categorizer.categorize_work_orders()
- Generate quality report using quality_reporter.generate_quality_report()
- Print quality report summary to console (quality score, key metrics, recommendations)
- If output_file provided, save processed DataFrame to CSV
- Return tuple: (processed_df, quality_report)
- Add comprehensive error handling at each stage with informative messages
- Log pipeline progress: "Loading...", "Cleaning...", "Categorizing...", "Validating...", "Complete"

**main():**
- CLI entry point that runs pipeline on default input file
- Print quality report in formatted, human-readable way
- Exit with code 0 if quality_passed, code 1 if failed
- If __name__ == "__main__": main()
  </action>
  <verify>python -m src.pipeline.pipeline shows pipeline execution and quality report</verify>
  <done>Pipeline orchestrator integrates all components and provides CLI interface with quality validation</done>
</task>

<task type="auto">
  <name>Task 3: Add pipeline documentation</name>
  <files>README.md</files>
  <action>
Create README.md with:
- Project title: Work Order Cost Reduction Analysis Pipeline
- Overview: Analyzes adhoc work order data to identify cost reduction opportunities
- Phase 1 completion status: Data pipeline foundation complete
- Setup instructions:
  - pip install -r requirements.txt
- Usage:
  - python -m src.pipeline.pipeline (runs full pipeline on input data)
  - Shows quality report output
- Project structure:
  - src/pipeline/data_loader.py - loads and validates CSV
  - src/pipeline/data_cleaner.py - cleans and standardizes data
  - src/pipeline/categorizer.py - normalizes equipment categories
  - src/pipeline/quality_reporter.py - generates quality metrics
  - src/pipeline/pipeline.py - orchestrates full pipeline
- Data quality metrics explained (completeness, consistency, outliers, coverage)
- Next steps: Phase 2 will add equipment category analysis
  </action>
  <verify>cat README.md shows project documentation</verify>
  <done>README documents pipeline usage, structure, and quality metrics</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] src/pipeline/quality_reporter.py calculates all quality metrics
- [ ] src/pipeline/pipeline.py orchestrates full data pipeline
- [ ] python -m src.pipeline.pipeline runs successfully
- [ ] Quality report displays completeness, consistency, outlier, and coverage metrics
- [ ] README.md documents setup and usage
</verification>

<success_criteria>

- All tasks completed
- Quality reporter provides comprehensive data assessment
- Integrated pipeline runs end-to-end without errors
- Quality report helps validate data readiness for analysis
- Documentation guides usage
  </success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline-foundation/01-04-SUMMARY.md`
</output>
