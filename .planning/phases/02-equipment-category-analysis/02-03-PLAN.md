---
phase: 02-equipment-category-analysis
plan: 03
type: execute
wave: 3
depends_on: ["02-02"]
files_modified: [src/analysis/equipment_ranker.py, src/analysis/analysis_pipeline.py, tests/test_equipment_ranker.py]
autonomous: true
---

<objective>
Create ranking system that prioritizes high-maintenance equipment by cost impact and provides actionable threshold recommendations.

Purpose: Transform outlier flags into prioritized list of equipment for cost reduction action, combining frequency, cost, and business impact.
Output: Equipment ranker that scores and ranks equipment, plus integrated analysis pipeline orchestrating frequency → outlier → ranking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-equipment-category-analysis/02-01-SUMMARY.md
@.planning/phases/02-equipment-category-analysis/02-02-SUMMARY.md

**From Plan 02-01:**
- Equipment frequencies with work_orders_per_month, avg_cost, avg_completion_days

**From Plan 02-02:**
- Outlier detection with is_outlier_consensus flag
- Z-score, IQR, percentile flags available

**Core value from PROJECT:**
Stakeholders can confidently act on identified opportunities - need clear prioritization

**Ranking factors:**
- Frequency (work_orders_per_month): Higher = more repairs needed
- Cost impact (total_work_orders * avg_cost): Financial impact
- Outlier status: Statistical significance
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ranking and scoring</name>
  <files>src/analysis/equipment_ranker.py</files>
  <action>
Create equipment_ranker.py with prioritization functions:

**calculate_cost_impact(outlier_df):**
- Add cost_impact column: total_work_orders * avg_cost
- This represents total maintenance spend for equipment over timespan
- Handle missing avg_cost (use 0 for cost_impact)
- Return DataFrame with cost_impact

**calculate_priority_score(outlier_df):**
- Normalize metrics to 0-1 scale within each category:
  - freq_score: (work_orders_per_month - cat_min) / (cat_max - cat_min)
  - cost_score: (cost_impact - cat_min) / (cat_max - cat_min)
  - outlier_score: 1.0 if is_outlier_consensus else 0.5 if any outlier flag else 0.0
- Calculate weighted priority_score: (freq_score * 0.4) + (cost_score * 0.4) + (outlier_score * 0.2)
- Weights: frequency and cost equally important (40% each), outlier status adds confidence (20%)
- Add priority_score column (0-1 range, higher = more urgent)
- Return DataFrame with scores

**rank_equipment(outlier_df):**
- Calculate cost impact and priority scores
- Sort by priority_score descending within each category
- Add category_rank column: rank within category (1 = highest priority)
- Add overall_rank column: rank across all categories
- Filter to outliers only (is_outlier_consensus=True) for focused results
- Return ranked DataFrame

**identify_thresholds(ranked_df):**
- Analyze ranked outliers to suggest thresholds:
  - frequency_threshold: median work_orders_per_month of consensus outliers
  - cost_threshold: median cost_impact of consensus outliers
  - percentile_threshold: typically 90th percentile (already used)
- Return dict with threshold recommendations for future analysis
- Include rationale: "Equipment exceeding [X] work orders/month in their category warrant review"
  </action>
  <verify>python -c "from src.analysis.equipment_ranker import rank_equipment; from src.analysis.outlier_detector import detect_outliers; from src.analysis.frequency_analyzer import calculate_equipment_frequencies; from src.pipeline.pipeline import run_pipeline; df, _ = run_pipeline('input/adhoc_wo_20240101_20250531.xlsx - in.csv'); freq = calculate_equipment_frequencies(df); outliers = detect_outliers(freq); ranked = rank_equipment(outliers); print(f'{len(ranked)} high-priority equipment identified')" shows ranked count</verify>
  <done>Ranking system scores equipment by frequency, cost impact, and outlier status with actionable prioritization</done>
</task>

<task type="auto">
  <name>Task 2: Create integrated analysis pipeline</name>
  <files>src/analysis/analysis_pipeline.py</files>
  <action>
Create analysis_pipeline.py to orchestrate complete analysis:

**run_equipment_analysis(input_file):**
- Load and prepare data using data pipeline:
  - Call run_pipeline() from src.pipeline.pipeline
- Calculate frequencies:
  - Call calculate_equipment_frequencies()
  - Call calculate_category_statistics() for baselines
- Detect outliers:
  - Call detect_outliers() with all methods
- Rank equipment:
  - Call rank_equipment() to get prioritized list
  - Call identify_thresholds() for recommendations
- Return tuple: (ranked_equipment_df, category_stats_df, thresholds_dict)
- Add comprehensive logging at each stage

**main():**
- CLI entry point: runs equipment analysis on default input file
- Print summary statistics:
  - Total equipment analyzed
  - Consensus outliers found
  - Top 5 highest-priority equipment (show: Equipment_ID, category, work_orders_per_month, cost_impact, priority_score)
  - Recommended thresholds
- If __name__ == "__main__": main()
  </action>
  <verify>python -m src.analysis.analysis_pipeline shows analysis execution and top equipment list</verify>
  <done>Integrated pipeline orchestrates frequency → outlier → ranking with CLI interface</done>
</task>

<task type="auto">
  <name>Task 3: Create tests for ranking logic</name>
  <files>tests/test_equipment_ranker.py</files>
  <action>
Create tests/test_equipment_ranker.py with pytest tests:

**test_calculate_cost_impact:**
- Sample data: equipment with total_work_orders=10, avg_cost=1000
- Verify cost_impact = 10,000

**test_calculate_priority_score_weighting:**
- Sample equipment with known normalized scores
- Verify weighted sum: 0.4*freq + 0.4*cost + 0.2*outlier
- Verify priority_score in [0, 1] range

**test_rank_equipment:**
- Multiple equipment with different priority scores
- Verify equipment sorted by priority_score descending
- Verify category_rank and overall_rank assigned correctly
- Verify only consensus outliers included in results

**test_identify_thresholds:**
- Sample ranked equipment with known frequencies and costs
- Verify thresholds calculated from medians
- Verify threshold dict structure

Use simple assert statements with deterministic test data.
  </action>
  <verify>pytest tests/test_equipment_ranker.py -v shows all tests passing</verify>
  <done>Test suite validates ranking calculations and threshold identification</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] src/analysis/equipment_ranker.py implements scoring and ranking
- [ ] Priority score combines frequency, cost, and outlier status
- [ ] src/analysis/analysis_pipeline.py orchestrates full analysis
- [ ] python -m src.analysis.analysis_pipeline runs successfully
- [ ] pytest tests/test_equipment_ranker.py passes
- [ ] Top equipment list shows actionable priorities
</verification>

<success_criteria>

- All tasks completed
- Equipment ranked by cost reduction priority
- Thresholds identified for future analysis
- Integrated pipeline provides end-to-end analysis
- Clear, actionable output for stakeholders
  </success_criteria>

<output>
After completion, create `.planning/phases/02-equipment-category-analysis/02-03-SUMMARY.md`
</output>
